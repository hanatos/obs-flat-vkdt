#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable

#include "shared.glsl"
#include "config.h"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

layout(std140, set = 0, binding = 1) uniform params_t
{
  float merge_k;
  float merge_n;
  // blur0--3 to follow here but we don't care
} params;

layout(push_constant, std140) uniform push_t
{
  uint scale;
  uint it;
} push;

layout( // distance buffers
    set = 1, binding = 0
) uniform sampler2D img_dist[];

layout( // coarse offset buffer
    set = 1, binding = 1
) uniform sampler2D img_coff;

layout( // merged offset buffer
    set = 1, binding = 2
) uniform writeonly image2D img_out;

layout( // residual distance
    set = 1, binding = 3
) uniform writeonly image2D img_resid;

float dot9(float a[9], float b[9])
{
  return a[0]*b[0] + a[1]*b[1] + a[2]*b[2] +
         a[3]*b[3] + a[4]*b[4] + a[5]*b[5] +
         a[6]*b[6] + a[7]*b[7] + a[8]*b[8];
}

// merge offset buffers: pick one with smaller distance
void
main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID.xy);
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;

  // merge all offsets to find minimum distance
  // only one special case: do we have coarse or not (detect using scale):
  vec2 coff = vec2(0);
  if(push.scale > 0)
    coff = texture(img_coff, (ipos+.5)/vec2(push.scale*textureSize(img_coff, 0))).rg * push.scale;

  vec4 res1 = vec4(0, 0, 6500000, 1);

  float dist[25];
  int bi = 0;
  for(int i=0;i<25;i++)
    dist[i] = texelFetch(img_dist[i], ipos, 0).r;
  for(int i=0;i<25;i++)
    if(dist[i] < dist[bi]) bi = i;
  // prefer center for completely constant input
  if(dist[12] == dist[bi]) bi = 12;

  int offy = bi / 5;
  int offx = bi - offy * 5;
  offx -= 2; offy -= 2;

  res1 = vec4(coff + vec2(offx, offy), dist[bi], 1);

#ifndef DT_ALIGN_NO_QUADRIC
  // the mechanics here are intricate.
  // the coarsest levels are not stable because the motion there is not "local" enough
  // the finer levels tend to become unstable because the motion is too noisy/incoherent.

  // corner and edge cases don't get interpolated, sorry:
  if((offx > -2 || offx < 2 || offy > -2 || offy < 2) &&
     // (push.it <= 1)) // only refine finest two levels, others not stable enough
     (push.it == 0)) // only refine very last time
  { // internal coordinate, we have a surrounding set of points
    // find sub-pixel minimum by fitting a presumably positive semi definite
    // quadratic polynomial to the 2d field. this follows hasinoff [2016] sec 4
    // in their supplemental material.
    // D_sub_2 (eq 14) from the paper, linearised into one vector
    float D_sub_2[9];
    for(int jj=-1;jj<=1;jj++)
      for(int ii=-1;ii<=1;ii++)
        D_sub_2[3*(jj+1)+ii+1] = dist[bi + jj*5+ii];

    // filter banks:
    const float F_A11[] = float[](
        1/4.0, -2/4.0, 1/4.0,
        2/4.0, -4/4.0, 2/4.0,
        1/4.0, -2/4.0, 1/4.0
        );
    const float F_A22[] = float[](
        1/4.0,  2/4.0,  1/4.0,
       -2/4.0, -4/4.0, -2/4.0,
        1/4.0,  2/4.0,  1/4.0
        );
    const float F_A12[] = float[](
        1/4.0, 0, -1/4.0,
            0, 0,  0,
       -1/4.0, 0,  1/4.0
        );
    const float F_b1[] = float[](
       -1/8.0, 0, 1/8.0,
       -2/8.0, 0, 2/8.0,
       -1/8.0, 0, 1/8.0
        );
    const float F_b2[] = float[](
       -1/8.0, -2/8.0, -1/8.0,
        0/8.0,  0/8.0,  0/8.0,
        1/8.0,  2/8.0,  1/8.0
        );
    // unused because c irrelevant for us
    // const float F_c[] = float[](
    //   -1/16.0,  2/16.0, -1/16.0,
    //    2/16.0, 12/16.0,  2/16.0,
    //   -1/16.0,  2/16.0, -1/16.0
    // );

    float A[] = float[](
      dot9(F_A11, D_sub_2), dot9(F_A12, D_sub_2), 
      dot9(F_A12, D_sub_2), dot9(F_A22, D_sub_2));
    const float b[] = float[](
      dot9(F_b1, D_sub_2),
      dot9(F_b2, D_sub_2));
    // unused because we just need the min
    // const float c = dot9(F_c, D_sub_2);
#if 0 // i think this causes more trouble than it does good:
    // make A positive semi definite if it's not yet:
    A[0] = max(0.0, A[0]);
    A[3] = max(0.0, A[3]);
    if(A[0]*A[3] - A[1]*A[2] < 1e-3) A[1] = A[2] = 0.0;
#endif

    // now transform the 1/2xAx + bx + c form to
    // 1/2(x-mu) A (x-mu) + s
    // because we want to know mu.

    // mu = - A^-1 b
    //  s = c - muAmu/2

    float detA = A[0]*A[3] - A[1]*A[2];
    // if D_sub is constant, A will be zero and thus the determinant "small" (for small values of "small")
    // in this case we wat to switch off the refinement and stick to what was hopefully 0 already.
    if(detA > 1e-3)
    {
      vec2 mu = vec2(
          (A[3] * b[0] - A[1]*b[1])/detA,
          (A[0] * b[1] - A[2]*b[0])/detA);
      res1.xy -= clamp(mu, vec2(-1), vec2(1));
    }
    // else res1.xy = vec2(0); // happens all the time :(
  }
#endif

  imageStore(img_out, ipos, vec4(res1.xy, 0, 0));
  res1.z = max(params.merge_k*(res1.z - params.merge_n), 0.0);
  res1.z = res1.z/(1.0+res1.z); // fade out smoothly
  imageStore(img_resid, ipos, vec4(res1.z));
}

