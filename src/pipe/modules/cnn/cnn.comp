#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable
#extension GL_EXT_shader_16bit_storage    : enable
#extension GL_EXT_control_flow_attributes : enable
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : enable
#include "shared.glsl"
#include "config.h"

// we are processing tiles of WD x HT at a time.
// a workgroup of threads is created, one for each
// because then a 4x4x4 matrix muladd (tensor cores) can read a 4x4 matrix (4 adjacent pixels x 4 input channels) and multiply by 4x4 weights (input channels x output channels for given conv pos) and add to result (4 adjacent pixels x 4 output channels)

// we have max 16 output channels, each thread processes 4 at a time
layout(local_size_x = DT_CNN_TILE_WD, local_size_y = DT_CNN_TILE_HT, local_size_z = 1) in;

// layout(std140, set = 0, binding = 1) uniform params_t
// { } params;

layout( // input texture
    set = 1, binding = 0
) uniform sampler2D img_in;

layout( // network weights
    set = 1, binding = 1
) uniform sampler2D img_wgt;

layout( // output buffer
    set = 1, binding = 2
) uniform writeonly image2D img_out;

// intermediate layers, allocated for the maximum number of outputs
// reduce bank conflicts by increasing stride a bit:
#define SK 0
shared f16vec4 layer[4*(DT_CNN_TILE_WD+SK)*DT_CNN_TILE_HT];


f16vec4 read_input(
    ivec2 x,   // 2d index in tile
    uint ip,   // input number/4
    uint ni)   // number of inputs/4
{
  uint idx =
    clamp(x.x,0,DT_CNN_TILE_WD-1)+(DT_CNN_TILE_WD+SK)*
    clamp(x.y,0,DT_CNN_TILE_HT-1);
  return layer[ip + ni*idx];
}

void write_output(
    f16vec4 val, // value to set to
    uint idx,    // 2d index in tile, linearised scanline order
    uint op,     // output number/4
    uint no)     // number of outputs/4
{
  layer[op + no*idx] = val;
}

f16vec4 read_bias(
    uint ic, // number of input channels
    uint o,  // the output channel (start index of group of 4)
    uint y0) // the offset of the current layer
{
  return f16vec4(texelFetch(img_wgt, ivec2(9*ic, y0 + o/4), 0));
}

// read the weight matrix for a given convolution position k<9.
// returns 4x4 to be multiplied against column vectors of inputs
// arranged as [i, i+1, i+2, i+3]^t to yield output deltas to
// be summed onto [o, o+1, o+2, o+3]^t
f16mat4 read_mat(
    uint i,   // the input channel to process, start of a group of 4
    uint o,   // the output channels to process, start of a group of 4
    uint k,   // the 3x3 convolution mask index < 9
    uint y0)  // the offset in the weights texture for this layer
{
  // pack into matrix where column vectors are rgba (for output channels)
  // TODO: pre-swizzle input such that this is adjacent in memory:
  // TODO: for textures in a 2x2 block, for ssbo next to each other.
  return f16mat4(
      f16vec4(texelFetch(img_wgt, ivec2(9*(i+0)+k, y0+o/4), 0)),
      f16vec4(texelFetch(img_wgt, ivec2(9*(i+1)+k, y0+o/4), 0)),
      f16vec4(texelFetch(img_wgt, ivec2(9*(i+2)+k, y0+o/4), 0)),
      f16vec4(texelFetch(img_wgt, ivec2(9*(i+3)+k, y0+o/4), 0)));
}

// TODO: shmem skew
// TODO: opt tex layout
void
main()
{
  ivec2 ipos =
    ivec2(gl_WorkGroupID.xy * ivec2(
        DT_CNN_TILE_WD-2*DT_CNN_BORDER,
        DT_CNN_TILE_HT-2*DT_CNN_BORDER));
  // if start of tile is out of image we have nothing to do:
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;
  ipos += ivec2(gl_LocalInvocationID.xy) - ivec2(DT_CNN_BORDER, DT_CNN_BORDER); // add offset within the tile

  // initially fill 6 channels of layer[] with orig + 5x5 blur, sourced from img_in.
  const uint tidx = gl_LocalInvocationID.x + (DT_CNN_TILE_WD+SK) * gl_LocalInvocationID.y;

  // really 256 but that would overflow our numbers.
  const float scale = 128.0; // scale input for network
  f16vec3 blur;
  // XXX TODO: try different order in shared memory (tile first, then output)
  { // 5x5 scope
    f16vec4 res = f16vec4(scale*texture(img_in, (ipos+0.5)/vec2(textureSize(img_in, 0))));
    write_output(res, tidx, 0, 2);
    
    res = f16vec4(0.0);
    for(int j=-2;j<=2;j++) for(int i=-2;i<=2;i++)
    {
      const float16_t wgt[5] = {float16_t(2./16.), float16_t(4./16.), float16_t(6./16.), float16_t(4./16.), float16_t(2./16.)};
      f16vec4 tex = f16vec4(scale*texture(img_in, (ipos+vec2(i,j)+0.5)/vec2(textureSize(img_in, 0))));
      res += wgt[j+2]*wgt[i+2] * tex;
    }
    barrier();
    write_output(res, tidx, 1, 2);
    blur = res.rgb;
    barrier();
  }

  int off = 1; // current y coordinate in weights texture

  // XXX TODO: write the texture padded already?
  f16vec4 tmp_out[4];
  [[unroll]] for(int cout=0;cout<4;cout++)
  { // special case: C1: 6 input, 16 output channels
    f16vec4 res = read_bias(6, 4*cout, off);
    for(int j=-1;j<=1;j++) for(int i=-1;i<=1;i++)
    {
      f16mat4 m0 = read_mat(0, 4*cout, 3*(j+1)+i+1, off);
      f16mat4 m1 = read_mat(4, 4*cout, 3*(j+1)+i+1, off);
      f16vec4 v0 = read_input(ivec2(gl_LocalInvocationID) - ivec2(i,j), 0, 2);
      f16vec4 v1 = read_input(ivec2(gl_LocalInvocationID) - ivec2(i,j), 1, 2);
      res += m0 * f16vec4(v0.xyz, v1.x);
      res += m1 * f16vec4(v1.yz, 0.0, 0.0);
    }
    res *= mix(f16vec4(1.0), f16vec4(0.05), lessThan(res, f16vec4(0.0)));
    tmp_out[cout] = res;
  }
  off += 4;
  barrier();
  [[unroll]] for(int cout=0;cout<4;cout++)
    write_output(tmp_out[cout], tidx, cout, 4);
  barrier();

  // ci/co_cnt = 16 for this block
  for(int l=1;l<15;l++)
  { // inner 3x3 scope: C2..C15
    [[unroll]] for(int cout=0;cout<4;cout++)
    {
      f16vec4 res = read_bias(16, 4*cout, off);
      for(int j=-1;j<=1;j++) for(int i=-1;i<=1;i++) for(int ip=0;ip<4;ip++)
      {
        f16mat4 m = read_mat(4*ip, 4*cout, 3*(j+1)+i+1, off);
        res += m * read_input(ivec2(gl_LocalInvocationID) - ivec2(i,j), ip, 4);
      }
      // apply leaky relu
      res *= mix(f16vec4(1.0), f16vec4(0.05), lessThan(res, f16vec4(0.0)));
      tmp_out[cout] = res;
    }
    off += 4;
    barrier();
    [[unroll]] for(int cout=0;cout<4;cout++)
      write_output(tmp_out[cout], tidx, cout, 4);
    barrier(); // now all results are in place, carry on.
  }

  { // last layer C16 with three outputs and no relu
    f16vec4 res = read_bias(16, 0, off);
    for(int j=-1;j<=1;j++) for(int i=-1;i<=1;i++) for(int ip=0;ip<4;ip++)
    { // last 3x3
      f16mat4 m = read_mat(4*ip, 0, 3*(j+1)+i+1, off);
      res += m * read_input(ivec2(gl_LocalInvocationID) - ivec2(i,j), ip, 4);
    }
    barrier();
    write_output(res, tidx, 0, 1);
    barrier();
  }

  {
    // sum back to blurred input
    vec3 rgb = vec3(layer[tidx].rgb) + vec3(blur);
    // vec3 rgb = vec3(layer[2*tidx].rgb);
    // vec3 rgb = vec3(layer[4*tidx].rgb);
    // rgb = blur;
    // write back to output texture
    if(all(greaterThanEqual(gl_LocalInvocationID.xy, uvec2(DT_CNN_BORDER))) &&
        all(lessThan(gl_LocalInvocationID.xy, uvec2(DT_CNN_TILE_WD-DT_CNN_BORDER, DT_CNN_TILE_HT-DT_CNN_BORDER))) &&
        all(lessThan(ipos, imageSize(img_out))))
      imageStore(img_out, ipos, vec4(rgb/scale, 1));
  }
}
