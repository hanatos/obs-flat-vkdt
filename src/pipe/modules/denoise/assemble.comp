#version 460
#extension GL_GOOGLE_include_directive    : enable
#extension GL_EXT_nonuniform_qualifier    : enable

#include "shared.glsl"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

layout(std140, set = 0, binding = 1) uniform params_t
{
  float strength;
  float luma;
  float detail;
  int   gainmap;
} params;

layout(push_constant, std140) uniform push_t
{
  vec4  wb;
  vec4  black;
  vec4  white;
  ivec4 crop;
  float noise_a;
  float noise_b;
  uint  filters;
} push;

// 5 input scales
layout( set = 1, binding = 0) uniform sampler2D img_s0; // original image
layout( set = 1, binding = 1) uniform sampler2D img_s1; // one downsampling step
layout( set = 1, binding = 2) uniform sampler2D img_s2; // ..
layout( set = 1, binding = 3) uniform sampler2D img_s3;
layout( set = 1, binding = 4) uniform sampler2D img_s4; // four downsampling steps

layout( // output
    set = 1, binding = 5
) uniform writeonly image2D img_out;

void
main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;

  // go through all levels same as downsampling would, swizzling coordinates
  // on the go as done in down.comp. then pick up the scales accordingly.
  vec3 down4;
  // this is for srgb not rec2020, but whatever
  const mat3 rgb_to_yuv = mat3(
      0.299, -0.147, 0.615,
      0.587, -0.289, -0.515,
      0.114, 0.436, -0.100);
  vec3 orig = texelFetch(img_s0, ipos+push.crop.xy, 0).rgb;
  float test = 1.0;
  { // scope for registers
    ivec2 esi = ipos;
    ivec2 sz = textureSize(img_s1, 0).xy + ivec2(1);

    vec3 down0 = orig;
    // TODO: consider 2px padding radius for next iteration and mirror repeat!
    esi = esi / 2 + ivec2(esi.x & 1, esi.y & 1) * sz/2;
    vec4 down1rgba = texelFetch(img_s1, esi, 0);
    vec3 down1 = down1rgba.rgb;
    test = down1rgba.w;
    esi = esi / 2 + ivec2(esi.x & 1, esi.y & 1) * sz/2;
    vec3 down2 = texelFetch(img_s2, esi, 0).rgb;
    esi = esi / 2 + ivec2(esi.x & 1, esi.y & 1) * sz/2;
    vec3 down3 = texelFetch(img_s3, esi, 0).rgb;
    esi = esi / 2 + ivec2(esi.x & 1, esi.y & 1) * sz/2;
    down4 = texelFetch(img_s4, esi, 0).rgb;

    // compute wavelet coefficients for this pixel
    // normalise these by dividing out expected noise std dev:
    // our data is now normalised to [0, 1] already:
    // the noise model is  sigma^2 = a + x*b  where x is the uint16_t scale raw value minus the raw black level.
    // this means we have to re-scale our normalised value to the previous white level.
    // const float scale = 65535.0*(push.white.g-push.black.g);
    // const float sigma = max(1e-8, 5.0 * sqrt(push.noise_a + scale*max(down2.x, 0.0)*push.noise_b)/scale);
    const float scale = 65535.0;
    // keep this in sync with down.comp!
    const float sigma = max(1e-8, 20.0 * sqrt(push.noise_a + scale*max(down2.g, 0.0)*push.noise_b)/scale);
    // Var(aX) = a^2 * Var(X), so the factors of our filter taps come in squared here:
    // var band = 
    //  (t*t + (1.0-t)*(1.0-t)*4.0/16.0*(
    //  0.2*0.4*0.2*0.4 + 0.2*0.6*0.2*0.6 + 0.8*0.4*0.8*0.4 + 0.8*0.6*0.8*0.6)) * base var
    // => sigma' ~= 0.29165 * base sigma
    // mosaiced images are preprocessed by averaging a block of greens.
    // for xtrans these are 5 greens, so std dev / sqrt(5), bayer / sqrt(2).
    // demosaiced images have way less noise to begin with, so we should tune down variance, too!
    float block = push.filters == 0u ? 1.0 : (push.filters == 9u ? 2.23607 : 1.414213);
    const float b0 = 0.7000/block;
    const float b1 = 0.4900/block;
    const float b2 = 0.3430/block;
    const float b3 = 0.2401/block;
    down0 = (down0 - down1)/(sigma*b0);
    down1 = (down1 - down2)/(sigma*b1);
    down2 = (down2 - down3)/(sigma*b2);
    down3 = (down3 - down4)/(sigma*b3);

    // TODO: downweight coarser scales:
    // TODO: absolutely needs softer falloff
    // xi-squared statistic for iid unit variance:
    // float xi2 = 10.0*(down0.x*down0.x + down1.x*down1.x + down2.x*down2.x + down3.x*down3.x - 4.0); // * (n-1) = 3 really
    // TODO: compute true probability that these are indeed iid wrt some p value
    // (we are currently using same fake gaussian instead of a xi^2 statistic)

    // detects some high contrast edges by just thresholding the total energy in all channels.
    // apparently good for the writing on the signposts:
    // float xi2 = (down0.x*down0.x + down1.x*down1.x + down2.x*down2.x + down3.x*down3.x);
    // test = max(0.0, xi2 - 2.0);

    // we know pure noise should be gaussian with sigma = 1.0 on all bands.
    // a signal (not represented by our edge stopping yet) should have larger magnitude for finer scales, and possibly lower for
    // coarser scales.
    // float score = dot((down0 - 1.0),vec3(1)) + dot((down1 - 1.0),vec3(1));//
    // + dot((1.0-down2),vec3(1)) + dot((1.0-down3),vec3(1));
    // this detects (inversely) where edge stopping took place (black at some other edges)
    // also: edge stopping seems to fire just fine on the writing on the signs for noise (400,0) or so
    // test = length(down0) + length(down1) + length(down2) + length(down3);
    // test = test/(test+1.0);
    // test = 0.0;
    float d0 = length(down0), d1 = length(down1), d2 = length(down2), d3 = length(down3);
    float slope = ((d3 - d0)/3.0 + (d2 - d1)/1.0 + (d1 - d0)/1.0 + (d3-d2)/1.0 + (d2-d0)/2.0 + (d3-d1)/2.0)/6.0;
    // if(push.filters == 9)
    {
      test = max(0, -slope);
      test = max(0.0, 1.0-test);
      test = pow(test, 16.0);
      test = clamp(1.5*test, 0.0, 1.0);
    }

    // test = 0.5 + 0.5*xi2/sqrt(xi2*xi2+1.0);
    // wavelet shrinkage and re-assembly:
    // test = xi2/(xi2+10.);//.07*xi2;//exp(- 4.0*xi2); // fake Xi2
    // float test = exp(- 0.008*sqrt(xi2)); // fake Xi2
    // bayes shrink would be T = sigma_noise^2 / sigma_signal
    // maybe consider that sigma_channel^2 scales as 1/f^2 with frequency f for natural images?
    // we assume sigma_noise = frac * sigma_signal and cancel the two.
    // since we rescaled the bands to unit noise variance, the threshold is
    // just a (user) constant and the edge shielding term:
    vec3 thrs0 = vec3(params.strength);
    vec3 thrs;
    vec3 tt = vec3(0.0);
    const float ht = 2.0;
    thrs = mix(thrs0, vec3(10000.0), bvec3(abs(down3.x) > ht));
    tt = min(vec3(1.0), abs(down3)/(2*thrs));
    down4 += sigma * b3 * sign(down3) * mix(max(abs(down3) - thrs, vec3(0.0)), abs(down3), tt);
    thrs = mix(thrs0, vec3(10000.0), bvec3(abs(down2.x) > ht));
    tt = min(vec3(1.0), abs(down2)/(2*thrs));
    down4 += sigma * b2 * sign(down2) * mix(max(abs(down2) - thrs, vec3(0.0)), abs(down2), tt);
    thrs = mix(thrs0, vec3(10000.0), bvec3(abs(down1.x) > ht));
    tt = min(vec3(1.0), abs(down1)/(2*thrs));
    down4 += sigma * b1 * sign(down1) * mix(max(abs(down1) - thrs, vec3(0.0)), abs(down1), tt);
    thrs = mix(thrs0, vec3(10000.0), bvec3(abs(down0.x) > ht));
    tt = min(vec3(1.0), abs(down0)/(2*thrs));
    down4 += sigma * b0 * sign(down0) * mix(max(abs(down0) - thrs, vec3(0.0)), abs(down0), tt);
  }

  vec3 yuv  = rgb_to_yuv * ((down4 - push.black.rgb) / (push.white.rgb - push.black.rgb) * push.wb.rgb);
  vec3 yuvo = rgb_to_yuv * ((orig  - push.black.rgb) / (push.white.rgb - push.black.rgb) * push.wb.rgb);
  yuv.x = mix(yuvo.x, yuv.x, params.luma);
  vec3 rgb = (inverse(rgb_to_yuv) * yuv) / push.wb.rgb * (push.white.rgb - push.black.rgb) + push.black.rgb;

  imageStore(img_out, ipos, vec4(rgb, test));
}

