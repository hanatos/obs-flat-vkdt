#version 460
#extension GL_GOOGLE_include_directive    : enable

#include "shared.glsl"
#include "shared/dtucs.glsl"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

layout(std140, set = 0, binding = 1) uniform params_t
{
  vec4  mul;               // camera white balance (r,g,b, exposure)
  mat3  cam_to_rec2020;    // camera matrix
  uvec4 N;                 // number of patches <= 24
  mat3  rbf_P;             // rbf matrix part
  vec4  rbf_c[24];         // rbf coefficients
  vec4  rbf_p[24];         // rbf positions
  float temp;              // colour temperature for wb 0:2856 1:6504
  uint  colour_mode;       // 0-matrix 1-clut
  float saturation;        // multiplier on chroma
  uint  pick_mode;         // what do we do with the colour picked input?
  uint  gamut_mode;        // 0 nothing, 1 spec locus, 2 rec2020, 3, rec709
} params;

layout(push_constant, std140) uniform push_t
{
  int have_clut;
  int have_pick;
  int have_abney; // only set if we have both img_abney and img_spectra
} push;


layout( // input
    set = 1, binding = 0
) uniform sampler2D img_in;

layout( // output
    set = 1, binding = 1
) uniform writeonly image2D img_out;

layout( // if have_clut, the colour lookup table is here
    set = 1, binding = 2
) uniform sampler2D img_clut;

layout( // picked colour if any.
    set = 1, binding = 3
) uniform sampler2D img_pick; // does this need to be a usampler on amd?

layout( // if have_abney, this contains the hue constancy map
    set = 1, binding = 4
) uniform sampler2D img_abney;

layout( // if have_abney, this contains the spectral upsampling table
    set = 1, binding = 5
) uniform sampler2D img_spectra;


vec3 // return adapted rec2020
cat16(vec3 rec2020_d65, vec3 rec2020_src, vec3 rec2020_dst)
{
  // these are the CAT16 M^{-1} and M matrices.
  // we use the standalone adaptation as proposed in
  // Smet and Ma, "Some concerns regarding the CAT16 chromatic adaptation transform",
  // Color Res Appl. 2020;45:172â€“177.
  // these are XYZ to cone-like
  const mat3 M16i = transpose(mat3(
       1.86206786, -1.01125463,  0.14918677,
       0.38752654,  0.62144744, -0.00897398,
      -0.01584150, -0.03412294,  1.04996444));
  const mat3 M16 = transpose(mat3(
       0.401288, 0.650173, -0.051461,
      -0.250268, 1.204414,  0.045854,
      -0.002079, 0.048952,  0.953127));
  const mat3 rec2020_to_xyz = mat3(
    6.36958048e-01, 2.62700212e-01, 4.20575872e-11,
    1.44616904e-01, 6.77998072e-01, 2.80726931e-02,
    1.68880975e-01, 5.93017165e-02, 1.06098506e+00);

  const vec3 cl_src = M16 * rec2020_to_xyz * rec2020_src;
  const vec3 cl_dst = M16 * rec2020_to_xyz * rec2020_dst;
  vec3 cl = M16 * rec2020_to_xyz * rec2020_d65;
  cl *= cl_dst / cl_src;
  return inverse(rec2020_to_xyz) * M16i * cl;
}


float
kernel(vec3 ci, vec3 p)
{ // thinplate spline kernel
  float r2 = dot(ci-p, ci-p);
  return sqrt(r2);
  // if(r2 < 1e-8) return 0.0;
  // return r2 * sqrt(r2);
  // return r2 * log(r2);
}

void tri2quad(inout vec2 tc)
{
  tc.y = tc.y / (1.0-tc.x);
  tc.x = (1.0-tc.x)*(1.0-tc.x);
}

vec3 process_clut(vec3 rgb)
{
  float b = rgb.r+rgb.g+rgb.b;
  vec2 tc = rgb.rb/b;
  tri2quad(tc);
  tc.x /= 3.0;
  vec4 rbrb = vec4(texture(img_clut, tc).xy, texture(img_clut, tc+vec2(2.0/3.0, 0.0)).xy);
  vec2 L2 = texture(img_clut, tc + vec2(1.0/3.0, 0.0)).xy;
  float L = mix(L2.x, L2.y, params.temp);
  vec2 rb = mix(rbrb.xy, rbrb.zw, params.temp);
  rgb = vec3(rb.x, 1.0-rb.x-rb.y, rb.y);
  return rgb * L * b;
}

void
main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;

  vec3 rgb = texelFetch(img_in, ipos, 0).rgb; // read camera rgb
  float cam_lum = 1.5;
  vec3 picked_rgb = vec3(0.5);
  if(push.have_pick == 1 && params.pick_mode > 0)
  {
    const int i = 0; // which one of the colour pickers
    picked_rgb = vec3(
        // do we need this on amd?
        // uintBitsToFloat(texelFetch(img_pick, ivec2(i, 0), 0).r),
        // uintBitsToFloat(texelFetch(img_pick, ivec2(i, 1), 0).r),
        // uintBitsToFloat(texelFetch(img_pick, ivec2(i, 2), 0).r));
        texelFetch(img_pick, ivec2(i, 0), 0).r,
        texelFetch(img_pick, ivec2(i, 1), 0).r,
        texelFetch(img_pick, ivec2(i, 2), 0).r);
    cam_lum = dot(vec3(1), picked_rgb);
  }

  // process camera rgb to rec2020:
  if(params.colour_mode == 0 || push.have_clut == 0)
    rgb = params.cam_to_rec2020 * rgb;
  else rgb = process_clut(rgb);

  if(push.have_pick == 1 && (params.pick_mode & 1) != 0)
  { // spot wb
    if(params.colour_mode == 0 || push.have_clut == 0)
      picked_rgb = params.cam_to_rec2020 * picked_rgb;
    else
      picked_rgb = process_clut(picked_rgb);
    picked_rgb /= picked_rgb.g;
    rgb = cat16(rgb, picked_rgb, params.mul.rgb);
  } // regular white balancing
  else rgb = cat16(rgb, vec3(1.0), params.mul.rgb);

  if(push.have_pick == 1 && (params.pick_mode & 2) != 0)
  { // deflicker based on input patch
    rgb *= 1.5/cam_lum;
  }
  rgb *= params.mul.w; // exposure correction

  if(params.N.x > 0)
  { // now rbf part:
    vec3 co = params.rbf_P * rgb;
    uint N = clamp(params.N.x, 0, 24);
    for(int i=0;i<N;i++) co += params.rbf_c[i].rgb * kernel(rgb, params.rbf_p[i].rgb);
    rgb = co;
  }

  // dt ucs saturation last so we don't mess with the rbf which is potentially
  // used for cc24 calibration
  if(push.have_abney == 0 && params.saturation != 1.0)
  { // cut a few cycles if not needed
    rgb = max(rgb, vec3(0));
    vec3 xyY = rec2020_to_xyY(rgb);
    vec3 JCH = xyY_to_dt_UCS_JCH(xyY, 1.0);
    JCH.y = clamp(JCH.y * params.saturation, 0, 1.0);
    xyY = dt_UCS_JCH_to_xyY(JCH, 1.0);
    rgb = xyY_to_rec2020(xyY);
  }
  else if(push.have_abney == 1 && (params.saturation != 1.0 || params.gamut_mode > 0))
  { // saturation with hue constancy by dominant wavelength and gamut compression
    vec3 xyY = rec2020_to_xyY(rgb);

    // lookup wavelength and saturation from spectral upsampling table:
    tri2quad(xyY.xy);
    vec4 lut = texture(img_spectra, xyY.xy);
    vec2 sl = vec2(lut.w, -lut.y / (2.0 * lut.x));

    // translate wavelength to y coordinate in abney table:
    float norm = (sl.y - 400.0)/(700.0-400.0) - 0.5;
    sl.y = 0.5*(0.5 + 0.5 * norm / sqrt(norm*norm+0.25));
    if(lut.x > 0.0) sl.y += 0.5;

    // this is where we would be at without bounds
    float m = params.saturation * sl.x;
    // but we want to compress input in [sl.x.. infty) into
    // the interval [sl.x .. max_sat.x]
    const ivec2 size = textureSize(img_abney, 0).xy;
    if(params.gamut_mode > 0)
    {
      float bound = 1.0;
      if(params.gamut_mode == 1)
      { // spectral locus
        bound = texelFetch(img_abney, ivec2(size.x-1, sl.y*size.y), 0).g;
      }
      else if(params.gamut_mode == 2)
      { // rec2020
        vec2 max_sat = texelFetch(img_abney, ivec2(size.x-1, sl.y*size.y), 0).rg;
        bound = max_sat.x;
        sl.x *= max_sat.x / max_sat.y; // adjust lower bound to spectral locus scaled into triangle
        m = params.saturation * sl.x;
      }
      else if(params.gamut_mode == 3)
      { // rec709
        vec2 max_sat = texelFetch(img_abney, ivec2(size.x-2, sl.y*size.y), 0).rg;
        bound = max_sat.x;
        sl.x *= max_sat.x / max_sat.y;
        m = params.saturation * sl.x;
      }
      if(params.saturation > 1.0)
        sl.x = mix(sl.x, bound, (m - sl.x)/(m - sl.x + 1.0));
      else sl.x = m;
      if(sl.x > bound) sl.x = bound; // clip to gamut
    }
    else sl.x = clamp(m, 0.0, (size.x-3.0)/size.x); // make sure we don't hit the last column (gamut limits stored there)
    xyY.xy = texture(img_abney, sl).rg; // use lambda/sat lut to get new xy chroma values
    rgb = xyY_to_rec2020(xyY);
  }

  imageStore(img_out, ipos, vec4(rgb, 1));
}
